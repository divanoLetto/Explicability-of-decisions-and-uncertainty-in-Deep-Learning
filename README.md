# Explicability of decisions and uncertainty in Deep Learning
## Authors: Lorenzo Mandelli
#### Universit√† degli Studi di Firenze | UiT The Arctic University of Norway 

---
![](https://img.shields.io/github/contributors/divanoletto/Explicability-of-decisions-and-uncertainty-in-Deep-Learning?color=light%20green) ![](https://img.shields.io/github/repo-size/divanoletto/Explicability-of-decisions-and-uncertainty-in-Deep-Learning)
---

## Introduction

One of the problems that exist in deep learning is the ability to **explain why an AI makes a particular decision**. <br/>
The models that through a series of computations produce a decision are treated as a black box: they are not able to give explanations on why they assume a certain behavior.<br/>
It is therefore useful to be able to elaborate methods that, given a model, are able to provide an interpretation of its behavior.<br/>
In this project we implemented methods that allow to explain the behavior of a model as a whole (**global methods**) or with respect to a specific decision (**local methods**).

## Results

## Installation

The following libraries are needed to run the code:

1. torch (version =  )
2. torchvision (version = )
3. matplotlib (version =  )
4. scikit-learn (version =  )
5. numpy 
6. scipy 

## Data preprocessing

The dataset is made up of 91 images each of a different class. 
In order to preprocess the dataset it is necessary to run the process_data.py file which splits the images into folders according to their class.

## Usage

In order to run the programs files for the first time using the default settings (those that yield the best results), simply run the following scripts:

1. 2b 
2. 2c
3. 2d
4. 2e
5. 2f
6. 2h
